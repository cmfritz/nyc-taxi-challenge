{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Data\n",
    "The data was obtained via the [TLC Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) website provided. Looking at the website, there is an API, however I chose to scrape the data available through the links on this page because of the time restraint and ease of access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of links from website provided\n",
    "url = 'https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content) # create soup of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before choosing what files to download, I wanted to get an idea of the files available. To do so, I:\n",
    "1. Created a list of all the links found on this page\n",
    "2. Identifed the links that contained keywords indicating it was a data file\n",
    "3. Create table of the URLs and corresponding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of links for data to scrape\n",
    "sources = ['yellow', 'green', 'fhv', 'fhvhv']\n",
    "keyword = 'trip+data'\n",
    "url_list = []\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    url = link.get('href')\n",
    "    for source in sources:\n",
    "        if (keyword in url) and (source+'_' in url):\n",
    "            year = url[-11:][:4]\n",
    "            month = url[-6:][:2]\n",
    "            filename = source + '-' + year + '-' + month + '.csv'\n",
    "            url_list.append([source, month, year, url, filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow</td>\n",
       "      <td>01</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://s3.amazonaws.com/nyc-tlc/trip+data/yel...</td>\n",
       "      <td>yellow-2021-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>01</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://s3.amazonaws.com/nyc-tlc/trip+data/gre...</td>\n",
       "      <td>green-2021-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fhv</td>\n",
       "      <td>01</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://nyc-tlc.s3.amazonaws.com/trip+data/fhv...</td>\n",
       "      <td>fhv-2021-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fhvhv</td>\n",
       "      <td>01</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://nyc-tlc.s3.amazonaws.com/trip+data/fhv...</td>\n",
       "      <td>fhvhv-2021-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yellow</td>\n",
       "      <td>02</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://s3.amazonaws.com/nyc-tlc/trip+data/yel...</td>\n",
       "      <td>yellow-2021-02.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source month  year                                                url  \\\n",
       "0  yellow    01  2021  https://s3.amazonaws.com/nyc-tlc/trip+data/yel...   \n",
       "1   green    01  2021  https://s3.amazonaws.com/nyc-tlc/trip+data/gre...   \n",
       "2     fhv    01  2021  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv...   \n",
       "3   fhvhv    01  2021  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv...   \n",
       "4  yellow    02  2021  https://s3.amazonaws.com/nyc-tlc/trip+data/yel...   \n",
       "\n",
       "             filename  \n",
       "0  yellow-2021-01.csv  \n",
       "1   green-2021-01.csv  \n",
       "2     fhv-2021-01.csv  \n",
       "3   fhvhv-2021-01.csv  \n",
       "4  yellow-2021-02.csv  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving a list of files for use in my analysis notebook\n",
    "file_info = pd.DataFrame(url_list, columns = ['source', 'month', 'year', 'url', 'filename'])\n",
    "file_info.to_csv('file_info.csv', index=False)\n",
    "file_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table now helps me easily organize the files I want. Now I can easily choose which files I want to download. I chose to use data from 2017 to current. My reasoning is that according to the [TLC Trip Records User Guide](https://www1.nyc.gov/assets/tlc/downloads/pdf/trip_record_user_guide.pdf), this is the year where they started to receive drop-off location for the FHV data. We need the data with the zone information, and also this should also give enough data to establish a pre-covid snapshot for years 2017 - 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files for years 2017 to now\n",
    "target_year = 2017\n",
    "for row in url_list:\n",
    "    if int(row[2]) >= target_year:\n",
    "        path = 'data/' + row[4]\n",
    "        csv = requests.get(row[3])\n",
    "        with open(path, 'wb') as file:\n",
    "        file.write(csv.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the download code takes a while to run, once it downloaded, I used a new notebook to analyze the data. This notebook can be found [HERE](Analyze.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
